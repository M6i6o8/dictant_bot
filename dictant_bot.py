import json
import random
import os
import requests
import time
import hashlib
import re
from datetime import datetime

# ===== –ü–û–ü–´–¢–ö–ê –ò–ú–ü–û–†–¢–ê GEMINI =====
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
    print("‚úÖ Gemini –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è Gemini –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
SENTENCES_FILE = 'sentences.json'
USED_SENTENCES_FILE = 'used_sentences.txt'
LAST_SENTENCE_FILE = 'last_sentence.json'

# API –∫–ª—é—á–∏
OPENROUTER_KEY = os.environ.get('OPENROUTER_KEY')
GEMINI_KEY = os.environ.get('GEMINI_KEY')
CEREBRAS_KEY = os.environ.get('CEREBRAS_KEY')

# URL-—ã API
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
CEREBRAS_URL = "https://api.cerebras.ai/v1/chat/completions"

# ===== –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ò–ó–í–õ–ï–ö–ê–¢–ï–õ–¨ JSON =====
def extract_json(text):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return None
    
    # –£–±–∏—Ä–∞–µ–º markdown-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    text = text.replace('```json', '').replace('```', '').replace('`', '').strip()
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ JSON –æ–±—ä–µ–∫—Ç–∞
    json_pattern = r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}'
    matches = re.findall(json_pattern, text)
    
    for json_str in matches:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–∞—Ä—Å–∏–Ω–≥–∞
        for attempt in [
            json_str,
            json_str.replace("'", '"'),
            json_str.replace('\n', ' ').replace('\r', ''),
            re.sub(r',\s*}', '}', json_str)
        ]:
            try:
                data = json.loads(attempt)
                if isinstance(data, dict):
                    return data
            except:
                continue
    return None

# ===== –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ë–ê–ó–û–ô =====
def load_sentences():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ JSON"""
    try:
        with open(SENTENCES_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['sentences']
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ sentences.json: {e}")
        return [
            {"id": 1, "en": "I like to read books", "ru": "–Ø –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å –∫–Ω–∏–≥–∏", "topic": "üìö –•–æ–±–±–∏", "difficulty": "–ª–µ–≥–∫–æ", "explanation": "Present Simple –¥–ª—è –≤—ã—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–∏–≤—ã—á–∫–∏. –ü–æ—Å–ª–µ I –≥–ª–∞–≥–æ–ª –±–µ–∑ –æ–∫–æ–Ω—á–∞–Ω–∏–π."},
            {"id": 2, "en": "She works as a doctor", "ru": "–û–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Ä–∞—á–æ–º", "topic": "üíº –†–∞–±–æ—Ç–∞", "difficulty": "–ª–µ–≥–∫–æ", "explanation": "Present Simple. –ü–æ—Å–ª–µ she/he/it –¥–æ–±–∞–≤–ª—è–µ–º -s –∫ –≥–ª–∞–≥–æ–ª—É."},
            {"id": 3, "en": "They are playing football now", "ru": "–û–Ω–∏ —Å–µ–π—á–∞—Å –∏–≥—Ä–∞—é—Ç –≤ —Ñ—É—Ç–±–æ–ª", "topic": "‚öΩ –°–ø–æ—Ä—Ç", "difficulty": "—Å—Ä–µ–¥–Ω–µ", "explanation": "Present Continuous (are + playing) –¥–ª—è –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å."}
        ]

def load_used_ids():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID"""
    try:
        if os.path.exists(USED_SENTENCES_FILE):
            with open(USED_SENTENCES_FILE, 'r') as f:
                content = f.read().strip()
                if content:
                    return set(map(int, content.split(',')))
        return set()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID: {e}")
        return set()

def save_used_ids(used_ids):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID"""
    try:
        with open(USED_SENTENCES_FILE, 'w') as f:
            f.write(','.join(map(str, used_ids)))
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(used_ids)} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

def mark_as_used(sentence):
    """–ü–æ–º–µ—á–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ"""
    used_ids = load_used_ids()
    
    if 'id' not in sentence:
        text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
        sentence['id'] = int(text_hash, 16) % 1000000
    
    used_ids.add(sentence['id'])
    save_used_ids(used_ids)
    print(f"üìù –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ (ID: {sentence['id']})")
    return sentence['id']

def is_used(sentence):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    used_ids = load_used_ids()
    
    if 'id' in sentence:
        return sentence['id'] in used_ids
    
    text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
    fake_id = int(text_hash, 16) % 1000000
    return fake_id in used_ids

# ===== –§–£–ù–ö–¶–ò–ò –°–û–•–†–ê–ù–ï–ù–ò–Ø –ü–û–°–õ–ï–î–ù–ï–ì–û –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø =====
def save_last_sentence(sentence):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø–æ–ª–µ–π
        save_data = {
            'en': sentence['en'],
            'ru': sentence['ru'],
            'topic': sentence.get('topic', '–¢–µ–º–∞'),
            'difficulty': sentence.get('difficulty', '–ª–µ–≥–∫–æ'),
            'explanation': sentence.get('explanation', '–†–∞–∑–±–æ—Ä –±—É–¥–µ—Ç –ø–æ–∑–∂–µ')
        }
        
        # –ü—Ä–æ–±—É–µ–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        with open(LAST_SENTENCE_FILE, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        print(f"‚úÖ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {LAST_SENTENCE_FILE}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Ä–µ–∞–ª—å–Ω–æ —Å–æ–∑–¥–∞–ª—Å—è
        if os.path.exists(LAST_SENTENCE_FILE):
            file_size = os.path.getsize(LAST_SENTENCE_FILE)
            print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
            return True
        else:
            print(f"‚ùå –§–∞–π–ª {LAST_SENTENCE_FILE} –Ω–µ —Å–æ–∑–¥–∞–ª—Å—è")
            return False
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {e}")
        return False

def load_last_sentence():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –æ—Ç–≤–µ—Ç–∞"""
    try:
        if not os.path.exists(LAST_SENTENCE_FILE):
            print(f"‚ö†Ô∏è –§–∞–π–ª {LAST_SENTENCE_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        file_size = os.path.getsize(LAST_SENTENCE_FILE)
        print(f"üìÅ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")
        
        if file_size == 0:
            print("‚ö†Ô∏è –§–∞–π–ª –ø—É—Å—Ç–æ–π")
            return None
        
        with open(LAST_SENTENCE_FILE, 'r', encoding='utf-8') as f:
            sentence = json.load(f)
        
        print(f"‚úÖ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {sentence.get('en', '')[:50]}...")
        return sentence
        
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return None

# ===== –§–£–ù–ö–¶–ò–ò –ì–ï–ù–ï–†–ê–¶–ò–ò =====
def generate_with_gemini():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Google Gemini (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1)"""
    if not GEMINI_AVAILABLE or not GEMINI_KEY:
        return None
    
    try:
        genai.configure(api_key=GEMINI_KEY)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        prompt = """–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –°–æ–∑–¥–∞–π —É—á–µ–±–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–±–æ—Ä–æ–º.
        
        –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
        - –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏
        - –£—Ä–æ–≤–µ–Ω—å: –æ—Ç –ª–µ–≥–∫–æ–≥–æ –¥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
        - –†–∞–∑–±–æ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–º –∏ –ø–æ–¥—Ä–æ–±–Ω—ã–º
        
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
        {
            "en": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (5-10 —Å–ª–æ–≤)",
            "ru": "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
            "topic": "—Ç–µ–º–∞ —Å —ç–º–æ–¥–∑–∏",
            "difficulty": "–ª–µ–≥–∫–æ/—Å—Ä–µ–¥–Ω–µ",
            "explanation": "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"
        }"""
        
        response = model.generate_content(prompt)
        generated = response.text
        print(f"üìù Gemini –æ—Ç–≤–µ—Ç: {generated[:150]}...")
        
        sentence = extract_json(generated)
        if sentence and all(field in sentence for field in ['en', 'ru', 'topic', 'explanation']):
            return sentence
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini –æ—à–∏–±–∫–∞: {type(e).__name__}")
    
    return None

def generate_with_cerebras():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Cerebras (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2)"""
    if not CEREBRAS_KEY:
        return None
    
    models = ["llama3.1-8b", "llama3.3-70b"]
    model = random.choice(models)
    
    prompt = """–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –≥—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Ä–∞–∑–±–æ—Ä–æ–º.
    
    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
    {
        "en": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
        "ru": "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
        "topic": "—Ç–µ–º–∞ —Å —ç–º–æ–¥–∑–∏",
        "difficulty": "–ª–µ–≥–∫–æ/—Å—Ä–µ–¥–Ω–µ",
        "explanation": "–ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
    }"""
    
    try:
        response = requests.post(
            CEREBRAS_URL,
            headers={
                "Authorization": f"Bearer {CEREBRAS_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.8,
                "max_tokens": 400
            },
            timeout=25
        )
        
        if response.status_code == 200:
            result = response.json()
            generated = result['choices'][0]['message']['content']
            print(f"üìù Cerebras –æ—Ç–≤–µ—Ç: {generated[:150]}...")
            
            sentence = extract_json(generated)
            if sentence and all(field in sentence for field in ['en', 'ru', 'topic', 'explanation']):
                return sentence
    except Exception as e:
        print(f"‚ö†Ô∏è Cerebras –æ—à–∏–±–∫–∞: {type(e).__name__}")
    
    return None

def generate_with_openrouter():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenRouter (–ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)"""
    if not OPENROUTER_KEY:
        return None
    
    models = [
        "openrouter/free",
        "arcee-ai/trinity-large-preview:free",
        "z-ai/glm-4.5-air:free"
    ]
    
    model = random.choice(models)
    
    prompt = """–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π —É—á–µ–±–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –∏ —Ä–∞–∑–±–æ—Ä–æ–º.
    
    –í–µ—Ä–Ω–∏ JSON:
    {
        "en": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
        "ru": "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
        "topic": "—Ç–µ–º–∞ —Å —ç–º–æ–¥–∑–∏",
        "difficulty": "–ª–µ–≥–∫–æ/—Å—Ä–µ–¥–Ω–µ",
        "explanation": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏"
    }"""
    
    try:
        response = requests.post(
            OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {OPENROUTER_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.8,
                "max_tokens": 400
            },
            timeout=25
        )
        
        if response.status_code == 200:
            result = response.json()
            generated = result['choices'][0]['message']['content']
            print(f"üìù OpenRouter –æ—Ç–≤–µ—Ç: {generated[:150]}...")
            
            sentence = extract_json(generated)
            if sentence and all(field in sentence for field in ['en', 'ru', 'topic', 'explanation']):
                return sentence
    except Exception as e:
        print(f"‚ö†Ô∏è OpenRouter –æ—à–∏–±–∫–∞: {type(e).__name__}")
    
    return None

# ===== –û–°–ù–û–í–ù–´–ï –§–£–ù–ö–¶–ò–ò =====
def get_unique_ai_sentence():
    """–ü—Ä–æ–±—É–µ—Ç –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ"""
    providers = [
        ("Gemini", generate_with_gemini),
        ("Cerebras", generate_with_cerebras),
        ("OpenRouter", generate_with_openrouter)
    ]
    
    for name, func in providers:
        print(f"\nü§ñ –ü—Ä–æ–±—É—é {name}...")
        sentence = func()
        if sentence:
            if not is_used(sentence):
                print(f"‚úÖ {name} —Å—Ä–∞–±–æ—Ç–∞–ª!")
                return sentence
            else:
                print(f"‚ö†Ô∏è {name} –≤—ã–¥–∞–ª —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
    
    return None

def get_unique_db_sentence():
    """–ë–µ—Ä–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ –±–∞–∑—ã"""
    sentences = load_sentences()
    if not sentences:
        return None
    
    used_ids = load_used_ids()
    available = [s for s in sentences if s['id'] not in used_ids]
    
    if not available:
        print("üîÑ –í—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ")
        save_used_ids(set())
        available = sentences
    
    sentence = random.choice(available)
    print(f"‚úÖ –í–∑—è—Ç–æ –∏–∑ –±–∞–∑—ã (ID: {sentence['id']})")
    return sentence

def send_telegram_message(text):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram"""
    if not BOT_TOKEN or not CHAT_ID:
        print("‚ùå –ù–µ—Ç BOT_TOKEN –∏–ª–∏ CHAT_ID")
        return None
    
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'text': text,
        'parse_mode': 'HTML'
    }
    
    try:
        print(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram...")
        response = requests.post(url, data=data, timeout=15)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('ok'):
                print("‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                return result
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ Telegram API: {result}")
        else:
            print(f"‚ùå HTTP –æ—à–∏–±–∫–∞: {response.status_code}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
    
    return None

# ===== –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø =====
def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "="*60)
    print("üöÄ –ó–ê–ü–£–°–ö –ë–û–¢–ê")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–∏
    print(f"\nüìã –ù–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–π:")
    print(f"   Gemini: {'‚úÖ' if GEMINI_KEY else '‚ùå'} (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞: {'‚úÖ' if GEMINI_AVAILABLE else '‚ùå'})")
    print(f"   Cerebras: {'‚úÖ' if CEREBRAS_KEY else '‚ùå'}")
    print(f"   OpenRouter: {'‚úÖ' if OPENROUTER_KEY else '‚ùå'}")
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –∑–∞–ø—É—Å–∫–∞
    run_type = os.environ.get('RUN_TYPE', 'unknown')
    print(f"üìå –¢–∏–ø –∑–∞–ø—É—Å–∫–∞: {run_type}")
    
    # –í—Ä–µ–º—è –¥–ª—è –ª–æ–≥–æ–≤
    current_hour = datetime.now().hour
    current_minute = datetime.now().minute
    print(f"üïê –í—Ä–µ–º—è UTC: {current_hour}:{current_minute}")
    print(f"üïê –í—Ä–µ–º—è –ú–°–ö: {current_hour+3}:{current_minute}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    print(f"üìÇ –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
    print(f"üìÇ –°–æ–¥–µ—Ä–∂–∏–º–æ–µ: {os.listdir('.')}")
    
    sentence = None
    
    # ===== –ó–ê–î–ê–ù–ò–ï =====
    if run_type == 'task':
        print("\nüîç –ì–ï–ù–ï–†–ò–†–£–ï–ú –ù–û–í–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï...")
        sentence = get_unique_ai_sentence()
        
        if not sentence:
            print("\nüìö –ü—Ä–æ–±—É—é –±–∞–∑—É...")
            sentence = get_unique_db_sentence()
        
        if not sentence:
            print("‚ùå –ù–ï–¢ –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø")
            return
        
        print(f"\n‚úÖ –í–´–ë–†–ê–ù–û:")
        print(f"   üá¨üáß {sentence['en']}")
        print(f"   üá∑üá∫ {sentence['ru']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        print("\nüíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ...")
        if save_last_sentence(sentence):
            print("‚úÖ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        else:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        message = f"üìù <b>–ï–ñ–ï–î–ù–ï–í–ù–´–ô –î–ò–ö–¢–ê–ù–¢</b>\n\n"
        message += f"<b>–¢–µ–º–∞:</b> {sentence['topic']}\n"
        message += f"<b>–°–ª–æ–∂–Ω–æ—Å—Ç—å:</b> {sentence.get('difficulty', '–ª–µ–≥–∫–æ')}\n\n"
        message += f"üá¨üáß <b>–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π:</b>\n"
        message += f"<i>{sentence['en']}</i>\n\n"
        message += f"‚è≥ <b>–û—Ç–≤–µ—Ç –∏ —Ä–∞–∑–±–æ—Ä –ø—Ä–∏–¥—É—Ç —á–µ—Ä–µ–∑ 10 –º–∏–Ω—É—Ç</b>"
        
        print("\nüì® –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ó–ê–î–ê–ù–ò–ï...")
    
    # ===== –û–¢–í–ï–¢ =====
    elif run_type == 'answer':
        print("\nüîç –ó–ê–ì–†–£–ñ–ê–ï–ú –°–û–•–†–ê–ù–ï–ù–ù–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï...")
        sentence = load_last_sentence()
        
        if not sentence:
            print("‚ö†Ô∏è –ù–ï–¢ –°–û–•–†–ê–ù–ï–ù–ù–û–ì–û –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ...")
            sentence = get_unique_ai_sentence()
            
            if not sentence:
                print("\nüìö –ü—Ä–æ–±—É—é –±–∞–∑—É...")
                sentence = get_unique_db_sentence()
            
            if not sentence:
                print("‚ùå –ù–ï–¢ –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø")
                return
            
            print(f"\n‚úÖ –°–ì–ï–ù–ï–†–ò–†–û–í–ê–ù–û –ù–û–í–û–ï:")
            print(f"   üá¨üáß {sentence['en']}")
            print(f"   üá∑üá∫ {sentence['ru']}")
        else:
            print(f"\n‚úÖ –ó–ê–ì–†–£–ñ–ï–ù–û:")
            print(f"   üá¨üáß {sentence['en']}")
            print(f"   üá∑üá∫ {sentence['ru']}")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        message = f"üìù <b>–ü–†–û–í–ï–†–ö–ê –î–ò–ö–¢–ê–ù–¢–ê</b>\n\n"
        message += f"üá¨üáß <b>–ë—ã–ª–æ:</b> {sentence['en']}\n"
        message += f"üá∑üá∫ <b>–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥:</b>\n"
        message += f"<i>{sentence['ru']}</i>\n\n"
        message += f"üìä <b>–ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä:</b>\n"
        message += f"{sentence.get('explanation', '–ü—Ä–æ–¥–æ–ª–∂–∞–π –ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è –∫–∞–∂–¥—ã–π –¥–µ–Ω—å!')}\n\n"
        message += f"üí™ –û—Ç–ª–∏—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã!"
        
        print("\nüì® –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –û–¢–í–ï–¢...")
    
    else:
        print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –∑–∞–ø—É—Å–∫–∞: {run_type}")
        return
    
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    result = send_telegram_message(message)
    
    if result:
        if run_type == 'task':
            # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –∑–∞–¥–∞–Ω–∏–µ
            mark_as_used(sentence)
        print("\n‚úÖ –í–°–ï –û–ü–ï–†–ê–¶–ò–ò –í–´–ü–û–õ–ù–ï–ù–´ –£–°–ü–ï–®–ù–û")
    else:
        print("\n‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –û–¢–ü–†–ê–í–ò–¢–¨ –°–û–û–ë–©–ï–ù–ò–ï")
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤
    print(f"\nüìÇ –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
    for f in os.listdir('.'):
        if f.endswith('.json') or f.endswith('.txt'):
            size = os.path.getsize(f) if os.path.exists(f) else 0
            print(f"   {f}: {size} –±–∞–π—Ç")
    
    print("="*60 + "\n")

if __name__ == "__main__":
    main()
