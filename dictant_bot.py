import json
import random
import os
import requests
import time
import hashlib
from datetime import datetime
import google.generativeai as genai  # –¥–ª—è Gemini

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
SENTENCES_FILE = 'sentences.json'
USED_SENTENCES_FILE = 'used_sentences.txt'

# API –∫–ª—é—á–∏ —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
OPENROUTER_KEY = os.environ.get('OPENROUTER_KEY')
GEMINI_KEY = os.environ.get('GEMINI_KEY')
GROQ_KEY = os.environ.get('GROQ_KEY')
CEREBRAS_KEY = os.environ.get('CEREBRAS_KEY')
MISTRAL_KEY = os.environ.get('MISTRAL_KEY')

# URL-—ã API
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"
CEREBRAS_URL = "https://api.cerebras.ai/v1/chat/completions"
MISTRAL_URL = "https://api.mistral.ai/v1/chat/completions"

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ (–ø–æ—Ä—è–¥–æ–∫ = –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
PROVIDERS = [
    {
        'name': 'OpenRouter',
        'enabled': bool(OPENROUTER_KEY),
        'type': 'openai',
        'url': OPENROUTER_URL,
        'key': OPENROUTER_KEY,
        'models': [
            "openrouter/free",
            "arcee-ai/trinity-large-preview:free",
            "z-ai/glm-4.5-air:free"
        ]
    },
    {
        'name': 'Google Gemini',
        'enabled': bool(GEMINI_KEY),
        'type': 'gemini',
        'key': GEMINI_KEY,
        'model': 'gemini-2.0-flash-exp'
    },
    {
        'name': 'Groq',
        'enabled': bool(GROQ_KEY),
        'type': 'openai',
        'url': GROQ_URL,
        'key': GROQ_KEY,
        'models': [
            "llama-3.3-70b-versatile",
            "mixtral-8x7b-32768",
            "gemma2-9b-it"
        ]
    },
    {
        'name': 'Cerebras',
        'enabled': bool(CEREBRAS_KEY),
        'type': 'openai',
        'url': CEREBRAS_URL,
        'key': CEREBRAS_KEY,
        'models': [
            "llama3.1-8b",
            "llama3.3-70b"
        ]
    },
    {
        'name': 'Mistral',
        'enabled': bool(MISTRAL_KEY),
        'type': 'mistral',
        'key': MISTRAL_KEY,
        'models': [
            "mistral-large-latest",
            "mistral-small-latest"
        ]
    }
]

def generate_with_gemini(provider):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Google Gemini"""
    try:
        genai.configure(api_key=provider['key'])
        model = genai.GenerativeModel(provider['model'])
        
        prompt = """–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –≤ —Ç–∞–∫–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ ```):
        {
            "en": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º (5-10 —Å–ª–æ–≤)",
            "ru": "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
            "topic": "—Ç–µ–º–∞ —Å —ç–º–æ–¥–∑–∏",
            "difficulty": "–ª–µ–≥–∫–æ"
        }
        """
        
        response = model.generate_content(prompt)
        generated = response.text
        
        # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç markdown
        cleaned = generated.replace('```json', '').replace('```', '').strip()
        start = cleaned.find('{')
        end = cleaned.rfind('}') + 1
        
        if start != -1 and end > start:
            sentence = json.loads(cleaned[start:end])
            if all(field in sentence for field in ['en', 'ru', 'topic']):
                return sentence
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini –æ—à–∏–±–∫–∞: {type(e).__name__}")
    return None

def generate_with_mistral(provider):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Mistral AI"""
    try:
        model = random.choice(provider['models'])
        
        response = requests.post(
            provider['url'],
            headers={
                "Authorization": f"Bearer {provider['key']}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [
                    {"role": "user", "content": """–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
                    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
                    {"en": "...", "ru": "...", "topic": "...", "difficulty": "–ª–µ–≥–∫–æ"}"""}
                ],
                "temperature": 0.8,
                "max_tokens": 150
            },
            timeout=15
        )
        
        if response.status_code == 200:
            result = response.json()
            generated = result['choices'][0]['message']['content']
            
            cleaned = generated.replace('```json', '').replace('```', '').strip()
            start = cleaned.find('{')
            end = cleaned.rfind('}') + 1
            
            if start != -1 and end > start:
                sentence = json.loads(cleaned[start:end])
                if all(field in sentence for field in ['en', 'ru', 'topic']):
                    return sentence
    except Exception as e:
        print(f"‚ö†Ô∏è Mistral –æ—à–∏–±–∫–∞: {type(e).__name__}")
    return None

def generate_with_openai(provider):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ API (OpenRouter, Groq, Cerebras)"""
    try:
        model = random.choice(provider['models'])
        
        response = requests.post(
            provider['url'],
            headers={
                "Authorization": f"Bearer {provider['key']}",
                "Content-Type": "application/json"
            },
            json={
                "model": model,
                "messages": [
                    {"role": "user", "content": """–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
                    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
                    {"en": "...", "ru": "...", "topic": "...", "difficulty": "–ª–µ–≥–∫–æ"}"""}
                ],
                "temperature": 0.8,
                "max_tokens": 150
            },
            timeout=15
        )
        
        if response.status_code == 200:
            result = response.json()
            generated = result['choices'][0]['message']['content']
            
            cleaned = generated.replace('```json', '').replace('```', '').strip()
            start = cleaned.find('{')
            end = cleaned.rfind('}') + 1
            
            if start != -1 and end > start:
                sentence = json.loads(cleaned[start:end])
                if all(field in sentence for field in ['en', 'ru', 'topic']):
                    return sentence
    except Exception as e:
        print(f"‚ö†Ô∏è {provider['name']} –æ—à–∏–±–∫–∞: {type(e).__name__}")
    return None

def generate_with_ai():
    """–ü—Ä–æ–±—É–µ—Ç –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –ø–æ –æ—á–µ—Ä–µ–¥–∏, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    
    for provider in PROVIDERS:
        if not provider['enabled']:
            continue
            
        print(f"\nü§ñ –ü—Ä–æ–±—É—é {provider['name']}...")
        
        if provider['type'] == 'gemini':
            sentence = generate_with_gemini(provider)
        elif provider['type'] == 'mistral':
            sentence = generate_with_mistral(provider)
        else:  # openai-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ
            sentence = generate_with_openai(provider)
        
        if sentence:
            print(f"‚úÖ {provider['name']} —Å—Ä–∞–±–æ—Ç–∞–ª!")
            return sentence
        
        time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏
    
    print("‚ùå –ù–∏ –æ–¥–∏–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª")
    return None

def load_sentences():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ JSON"""
    try:
        with open(SENTENCES_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['sentences']
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ sentences.json: {e}")
        return [
            {"id": 1, "en": "I like to read books", "ru": "–Ø –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å –∫–Ω–∏–≥–∏", "topic": "üìö –•–æ–±–±–∏", "difficulty": "–ª–µ–≥–∫–æ"},
            {"id": 2, "en": "She works as a doctor", "ru": "–û–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Ä–∞—á–æ–º", "topic": "üíº –†–∞–±–æ—Ç–∞", "difficulty": "–ª–µ–≥–∫–æ"},
            {"id": 3, "en": "They are playing football", "ru": "–û–Ω–∏ –∏–≥—Ä–∞—é—Ç –≤ —Ñ—É—Ç–±–æ–ª", "topic": "‚öΩ –°–ø–æ—Ä—Ç", "difficulty": "–ª–µ–≥–∫–æ"}
        ]

def load_used_ids():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID"""
    try:
        if os.path.exists(USED_SENTENCES_FILE):
            with open(USED_SENTENCES_FILE, 'r') as f:
                content = f.read().strip()
                if content:
                    return set(map(int, content.split(',')))
        return set()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID: {e}")
        return set()

def save_used_ids(used_ids):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID"""
    try:
        with open(USED_SENTENCES_FILE, 'w') as f:
            f.write(','.join(map(str, used_ids)))
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(used_ids)} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

def mark_as_used(sentence):
    """–ü–æ–º–µ—á–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ"""
    used_ids = load_used_ids()
    
    if 'id' not in sentence:
        text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
        sentence['id'] = int(text_hash, 16) % 1000000
    
    used_ids.add(sentence['id'])
    save_used_ids(used_ids)
    print(f"üìù –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ (ID: {sentence['id']})")
    return sentence['id']

def is_used(sentence):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    used_ids = load_used_ids()
    
    if 'id' in sentence:
        return sentence['id'] in used_ids
    
    text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
    fake_id = int(text_hash, 16) % 1000000
    return fake_id in used_ids

def get_unique_ai_sentence(max_attempts=2):
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ AI-–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    for attempt in range(max_attempts):
        print(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –∏–∑ {max_attempts}")
        sentence = generate_with_ai()
        if sentence:
            if not is_used(sentence):
                print("‚úÖ –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ AI-–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
                return sentence
            else:
                print("‚ö†Ô∏è –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —É–∂–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–µ...")
        time.sleep(1)
    return None

def get_unique_db_sentence():
    """–ë–µ—Ä–µ—Ç –Ω–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑ –±–∞–∑—ã"""
    sentences = load_sentences()
    if not sentences:
        print("‚ùå –ë–∞–∑–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø—É—Å—Ç–∞")
        return None
    
    used_ids = load_used_ids()
    print(f"üìä –í –±–∞–∑–µ: {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {len(used_ids)}")
    
    available = [s for s in sentences if s['id'] not in used_ids]
    
    if not available:
        print("üîÑ –í—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–Ω–æ–≤–æ")
        save_used_ids(set())
        available = sentences
    
    sentence = random.choice(available)
    print(f"‚úÖ –í–∑—è—Ç–æ –∏–∑ –±–∞–∑—ã (ID: {sentence['id']})")
    return sentence

def send_telegram_message(text):
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Telegram"""
    
    if not BOT_TOKEN or not CHAT_ID:
        print("‚ùå –ù–µ—Ç BOT_TOKEN –∏–ª–∏ CHAT_ID")
        return None
    
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    data = {
        'chat_id': CHAT_ID,
        'text': text,
        'parse_mode': 'HTML'
    }
    
    try:
        response = requests.post(url, data=data, timeout=15)
        
        if response.status_code == 200:
            result = response.json()
            if result.get('ok'):
                print("‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Telegram")
                return result
        return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {e}")
        return None

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "="*50)
    print("üöÄ –ó–ê–ü–£–°–ö –ë–û–¢–ê (–ú–£–õ–¨–¢–ò-–ü–†–û–í–ê–ô–î–ï–†)")
    print("="*50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–∏
    print(f"ü§ñ BOT_TOKEN: {'‚úÖ' if BOT_TOKEN else '‚ùå'}")
    print(f"üì¢ CHAT_ID: {'‚úÖ' if CHAT_ID else '‚ùå'}")
    print("\nüìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã:")
    for p in PROVIDERS:
        status = "‚úÖ" if p['enabled'] else "‚ùå"
        print(f"   {status} {p['name']}")
    
    current_hour = datetime.now().hour
    print(f"üïê –¢–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è UTC: {current_hour}:{datetime.now().minute}")
    
    # –î–ª—è —Ç–µ—Å—Ç–∞ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤—Ä–µ–º—è
    # if current_hour not in [6, 7]:
    #     print("‚è∞ –ù–µ –≤—Ä–µ–º—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏")
    #     return
    
    print("\nüîç –ò–©–ï–ú –£–ù–ò–ö–ê–õ–¨–ù–û–ï –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï...")
    
    sentence = None
    
    # –ü—Ä–æ–±—É–µ–º AI (–≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ –æ—á–µ—Ä–µ–¥–∏)
    if any(p['enabled'] for p in PROVIDERS):
        print("\nü§ñ –ü—Ä–æ–±—É—é AI –≥–µ–Ω–µ—Ä–∞—Ü–∏—é...")
        sentence = get_unique_ai_sentence()
    
    # –ï—Å–ª–∏ AI –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –±–µ—Ä–µ–º –∏–∑ –±–∞–∑—ã
    if not sentence:
        print("\nüìö –ò—Å–ø–æ–ª—å–∑—É—é –±–∞–∑—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π...")
        sentence = get_unique_db_sentence()
    
    if not sentence:
        print("‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –ü–û–õ–£–ß–ò–¢–¨ –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï")
        return
    
    print(f"\n‚úÖ –í–´–ë–†–ê–ù–û –ü–†–ï–î–õ–û–ñ–ï–ù–ò–ï:")
    print(f"   üá¨üáß {sentence['en']}")
    print(f"   üá∑üá∫ {sentence['ru']}")
    print(f"   üìö {sentence['topic']}")
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    message = f"üìù <b>–ï–ñ–ï–î–ù–ï–í–ù–´–ô –î–ò–ö–¢–ê–ù–¢</b>\n\n"
    message += f"<b>–¢–µ–º–∞:</b> {sentence['topic']}\n"
    message += f"<b>–°–ª–æ–∂–Ω–æ—Å—Ç—å:</b> {sentence.get('difficulty', '–ª–µ–≥–∫–æ')}\n\n"
    message += f"üá¨üáß <b>–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π:</b>\n"
    message += f"<i>{sentence['en']}</i>\n\n"
    message += f"‚úçÔ∏è –ü–∏—à–∏ —Å–≤–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏!"
    
    print("\nüì® –û–¢–ü–†–ê–í–õ–Ø–ï–ú –í TELEGRAM...")
    result = send_telegram_message(message)
    
    if result:
        mark_as_used(sentence)
        print("\n‚úÖ –í–°–ï –û–ü–ï–†–ê–¶–ò–ò –í–´–ü–û–õ–ù–ï–ù–´ –£–°–ü–ï–®–ù–û")
    else:
        print("\n‚ùå –ù–ï –£–î–ê–õ–û–°–¨ –û–¢–ü–†–ê–í–ò–¢–¨ –°–û–û–ë–©–ï–ù–ò–ï")
    
    print("="*50 + "\n")

if __name__ == "__main__":
    main()
