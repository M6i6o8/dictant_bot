import json
import random
import os
import requests
import time
from datetime import datetime
import hashlib

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
OPENROUTER_KEY = os.environ.get('OPENROUTER_KEY')
SENTENCES_FILE = 'sentences.json'
USED_SENTENCES_FILE = 'used_sentences.txt'

# OpenRouter API
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"

def load_sentences():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ JSON"""
    try:
        with open(SENTENCES_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['sentences']
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ sentences.json: {e}")
        return [
            {"id": 1, "en": "I like to read books", "ru": "–Ø –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å –∫–Ω–∏–≥–∏", "topic": "üìö –•–æ–±–±–∏", "difficulty": "–ª–µ–≥–∫–æ"},
            {"id": 2, "en": "She works as a doctor", "ru": "–û–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Ä–∞—á–æ–º", "topic": "üíº –†–∞–±–æ—Ç–∞", "difficulty": "–ª–µ–≥–∫–æ"},
            {"id": 3, "en": "They are playing football", "ru": "–û–Ω–∏ –∏–≥—Ä–∞—é—Ç –≤ —Ñ—É—Ç–±–æ–ª", "topic": "‚öΩ –°–ø–æ—Ä—Ç", "difficulty": "–ª–µ–≥–∫–æ"}
        ]

def load_used_ids():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID"""
    try:
        if os.path.exists(USED_SENTENCES_FILE):
            with open(USED_SENTENCES_FILE, 'r') as f:
                content = f.read().strip()
                if content:
                    return set(map(int, content.split(',')))
        return set()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID: {e}")
        return set()

def save_used_ids(used_ids):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID"""
    try:
        with open(USED_SENTENCES_FILE, 'w') as f:
            f.write(','.join(map(str, used_ids)))
        print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(used_ids)} –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö ID")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

def mark_as_used(sentence):
    """–ü–æ–º–µ—á–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ"""
    used_ids = load_used_ids()
    
    if 'id' not in sentence:
        text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
        sentence['id'] = int(text_hash, 16) % 1000000
    
    used_ids.add(sentence['id'])
    save_used_ids(used_ids)
    print(f"üìù –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–º–µ—á–µ–Ω–æ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–æ–µ (ID: {sentence['id']})")
    return sentence['id']

def is_used(sentence):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–æ—Å—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    used_ids = load_used_ids()
    
    if 'id' in sentence:
        return sentence['id'] in used_ids
    
    text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
    fake_id = int(text_hash, 16) % 1000000
    return fake_id in used_ids

def test_all_models():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ä–∞–±–æ—Ç–∞—é—â–∏—Ö"""
    
    print("\n" + "="*60)
    print("üî¨ –ù–ê–ß–ò–ù–ê–ï–ú –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –í–°–ï–• –ë–ï–°–ü–õ–ê–¢–ù–´–• –ú–û–î–ï–õ–ï–ô")
    print("="*60)
    
    # –í—Å–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ OpenRouter
    test_models = [
        # –¢–æ–ø –º–æ–¥–µ–ª–∏
        "openrouter/free",  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–æ—É—Ç–µ—Ä
        "arcee-ai/trinity-large-preview:free",
        "stepfun/step-3.5-flash:free",
        "z-ai/glm-4.5-air:free",
        "deepseek/deepseek-r1:free",
        "meta-llama/llama-3.3-70b-instruct:free",
        "google/gemma-3-27b-it:free",
        "z-ai/glm-5-pony-alpha:free",
        "nvidia/nemotron-3-nano:free",
        "nvidia/nemotron-nano-2-vl:free",
        "qwen/qwen3-235b-thinking:free",
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ
        "google/gemini-2.0-flash-exp:free",
        "deepseek/deepseek-chat:free",
        "meta-llama/llama-3.2-3b-instruct:free",
        "qwen/qwen-2.5-7b-instruct:free",
        "microsoft/phi-3.5-mini-128k-instruct:free",
        "mistralai/mistral-7b-instruct:free",
        "cognitivecomputations/dolphin-2.9-llama3-8b:free",
        "microsoft/phi-3-mini-128k-instruct:free",
        "google/gemma-2-9b-it:free",
        "cohere/command-r-plus-08-2024:free",
        "cohere/command-r-03-2024:free"
    ]
    
    working_models = []
    
    for i, model in enumerate(test_models, 1):
        print(f"\nüîç –¢–µ—Å—Ç {i}/{len(test_models)}: {model}")
        print("-" * 40)
        
        prompt = """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. 
        –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
        
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
        {
            "en": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
            "ru": "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
            "topic": "—Ç–µ–º–∞ —Å —ç–º–æ–¥–∑–∏",
            "difficulty": "–ª–µ–≥–∫–æ"
        }
        
        –ü—Ä–∏–º–µ—Ä: {"en": "I like coffee", "ru": "–Ø –ª—é–±–ª—é –∫–æ—Ñ–µ", "topic": "‚òï –ï–¥–∞", "difficulty": "–ª–µ–≥–∫–æ"}
        """
        
        try:
            response = requests.post(
                OPENROUTER_URL,
                headers={
                    "Authorization": f"Bearer {OPENROUTER_KEY}",
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://github.com/dictant_bot",
                    "X-Title": "English Dictant Bot"
                },
                json={
                    "model": model,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7,
                    "max_tokens": 150
                },
                timeout=15
            )
            
            print(f"üìä –°—Ç–∞—Ç—É—Å: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                # –ö–∞–∫–∞—è –º–æ–¥–µ–ª—å —Ä–µ–∞–ª—å–Ω–æ –æ—Ç–≤–µ—Ç–∏–ª–∞ (–¥–ª—è —Ä–æ—É—Ç–µ—Ä–∞)
                actual_model = result.get('model', model)
                
                generated = result['choices'][0]['message']['content']
                print(f"üìù –û—Ç–≤–µ—Ç: {generated[:100]}...")
                
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON
                cleaned = generated.replace('```json', '').replace('```', '').strip()
                start = cleaned.find('{')
                end = cleaned.rfind('}') + 1
                
                if start != -1 and end > start:
                    try:
                        sentence = json.loads(cleaned[start:end])
                        if all(field in sentence for field in ['en', 'ru', 'topic']):
                            print(f"‚úÖ‚úÖ‚úÖ –†–ê–ë–û–¢–ê–ï–¢! –†–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: {actual_model}")
                            working_models.append({
                                '–∑–∞–ø—Ä–æ—à–µ–Ω–Ω–∞—è': model,
                                '—Ä–µ–∞–ª—å–Ω–∞—è': actual_model,
                                '–ø—Ä–∏–º–µ—Ä': sentence['en'][:50]
                            })
                        else:
                            print("‚ùå –û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω—É–∂–Ω—ã—Ö –ø–æ–ª–µ–π")
                    except json.JSONDecodeError:
                        print("‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON")
                else:
                    print("‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ {response.status_code}: {response.text[:100]}")
                
        except Exception as e:
            print(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {type(e).__name__}")
        
        time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
    
    # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    print("\n" + "="*60)
    print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("="*60)
    
    if working_models:
        print(f"\n‚úÖ –ù–ê–ô–î–ï–ù–û –†–ê–ë–û–¢–ê–Æ–©–ò–• –ú–û–î–ï–õ–ï–ô: {len(working_models)}")
        print("\nüìã –°–ü–ò–°–û–ö –†–ê–ë–û–¢–ê–Æ–©–ò–• –ú–û–î–ï–õ–ï–ô:")
        for wm in working_models:
            print(f"   ‚Ä¢ {wm['–∑–∞–ø—Ä–æ—à–µ–Ω–Ω–∞—è']}")
            print(f"     ‚Üí –†–µ–∞–ª—å–Ω–∞—è: {wm['—Ä–µ–∞–ª—å–Ω–∞—è']}")
            print(f"     ‚Üí –ü—Ä–∏–º–µ—Ä: {wm['–ø—Ä–∏–º–µ—Ä']}...\n")
    else:
        print("\n‚ùå –ù–ï –ù–ê–ô–î–ï–ù–û –ù–ò –û–î–ù–û–ô –†–ê–ë–û–¢–ê–Æ–©–ï–ô –ú–û–î–ï–õ–ò")
    
    print("="*60)
    return working_models

def generate_with_openrouter():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É—è —Ä–∞–±–æ—á—É—é –º–æ–¥–µ–ª—å"""
    
    if not OPENROUTER_KEY:
        print("‚ùå –ù–µ—Ç API –∫–ª—é—á–∞ OpenRouter")
        return None
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –º–æ–¥–µ–ª–∏ (–æ–±–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞)
    working_models = [
        "openrouter/free",  # –ï—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç
        "deepseek/deepseek-r1:free",
        "google/gemini-2.0-flash-exp:free",
        "meta-llama/llama-3.3-70b-instruct:free"
    ]
    
    model = random.choice(working_models)
    print(f"ü§ñ –ò—Å–ø–æ–ª—å–∑—É—é –º–æ–¥–µ–ª—å: {model}")
    
    prompt = """–¢—ã - –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. 
    –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º –Ω–∞ —Ä—É—Å—Å–∫–∏–π.
    
    –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
    {
        "en": "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º",
        "ru": "–ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —Ä—É—Å—Å–∫–∏–π",
        "topic": "—Ç–µ–º–∞ —Å —ç–º–æ–¥–∑–∏",
        "difficulty": "–ª–µ–≥–∫–æ"
    }
    """
    
    try:
        response = requests.post(
            OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {OPENROUTER_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/dictant_bot",
                "X-Title": "English Dictant Bot"
            },
            json={
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.8,
                "max_tokens": 200
            },
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            actual_model = result.get('model', model)
            print(f"ü§ñ –†–µ–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å: {actual_model}")
            
            generated = result['choices'][0]['message']['content']
            cleaned = generated.replace('```json', '').replace('```', '').strip()
            
            start = cleaned.find('{')
            end = cleaned.rfind('}') + 1
            
            if start != -1 and end > start:
                sentence = json.loads(cleaned[start:end])
                if all(field in sentence for field in ['en', 'ru', 'topic']):
                    if 'difficulty' not in sentence:
                        sentence['difficulty'] = '–ª–µ–≥–∫–æ'
                    return sentence
        return None
    except:
        return None

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("\n" + "="*50)
    print("üöÄ –ó–ê–ü–£–°–ö –ë–û–¢–ê-–î–ï–¢–ï–ö–¢–ò–í–ê")
    print("="*50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–∏
    print(f"ü§ñ BOT_TOKEN: {'‚úÖ' if BOT_TOKEN else '‚ùå'}")
    print(f"üì¢ CHAT_ID: {'‚úÖ' if CHAT_ID else '‚ùå'}")
    print(f"üîë OPENROUTER_KEY: {'‚úÖ' if OPENROUTER_KEY else '‚ùå'}")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    working_models = test_all_models()
    
    # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∞–±–æ—á–µ–π –º–æ–¥–µ–ª—å—é
    if working_models and CHAT_ID and BOT_TOKEN:
        print("\nüì® –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∞–±–æ—á–µ–π –º–æ–¥–µ–ª—å—é...")
        sentence = generate_with_openrouter()
        if sentence:
            message = f"üìù <b>–¢–ï–°–¢ –° –†–ê–ë–û–ß–ï–ô –ú–û–î–ï–õ–¨–Æ</b>\n\n"
            message += f"<b>–¢–µ–º–∞:</b> {sentence['topic']}\n"
            message += f"üá¨üáß {sentence['en']}\n"
            message += f"üá∑üá∫ {sentence['ru']}"
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram (–∫–æ–¥ –æ—Ç–ø—Ä–∞–≤–∫–∏ –æ–ø—É—â–µ–Ω –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏)
            print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {sentence['en']}")
    
    print("\n" + "="*50)

if __name__ == "__main__":
    main()
