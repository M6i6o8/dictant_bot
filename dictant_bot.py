import json
import random
import os
import requests
import hashlib
import re
from datetime import datetime

# –ù–æ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ Gemini
try:
    from google import genai
    GEMINI_AVAILABLE = True
    print("‚úÖ –ù–æ–≤–∞—è Gemini –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
except ImportError:
    GEMINI_AVAILABLE = False
    print("‚ö†Ô∏è Gemini –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –Ω—É–∂–Ω–æ: pip install google-genai")

# ===== –ù–ê–°–¢–†–û–ô–ö–ò =====
BOT_TOKEN = os.environ.get('BOT_TOKEN')
CHAT_ID = os.environ.get('CHAT_ID')
SENTENCES_FILE = 'sentences.json'
USED_SENTENCES_FILE = 'used_sentences.txt'
LAST_SENTENCE_FILE = 'last_sentence.json'

OPENROUTER_KEY = os.environ.get('OPENROUTER_KEY')
GEMINI_KEY = os.environ.get('GEMINI_KEY')
CEREBRAS_KEY = os.environ.get('CEREBRAS_KEY')

OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
CEREBRAS_URL = "https://api.cerebras.ai/v1/chat/completions"

# –¢–∏–ø –∑–∞–ø—É—Å–∫–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ –º–∏–Ω—É—Ç–∞–º
current_minute = datetime.now().minute
RUN_TYPE = 'answer' if 10 <= current_minute < 20 else 'task'
print(f"üìå –¢–∏–ø –∑–∞–ø—É—Å–∫–∞: {RUN_TYPE} (–ø–æ –º–∏–Ω—É—Ç–µ {current_minute})")

# ===== –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ò–ó–í–õ–ï–ö–ê–¢–ï–õ–¨ JSON =====
def extract_json(text):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç JSON –∏–∑ –ª—é–±–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    if not text:
        return None
    
    text = text.replace('```json', '').replace('```', '').replace('`', '').strip()
    json_pattern = r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}'
    matches = re.findall(json_pattern, text)
    
    for json_str in matches:
        for attempt in [
            json_str,
            json_str.replace("'", '"'),
            json_str.replace('\n', ' ').replace('\r', ''),
            re.sub(r',\s*}', '}', json_str)
        ]:
            try:
                data = json.loads(attempt)
                if isinstance(data, dict):
                    return data
            except:
                continue
    return None

# ===== –§–£–ù–ö–¶–ò–ò –†–ê–ë–û–¢–´ –° –ë–ê–ó–û–ô =====
def load_sentences():
    try:
        with open(SENTENCES_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['sentences']
    except:
        return [
            {"id": 1, "en": "I like to read books", "ru": "–Ø –ª—é–±–ª—é —á–∏—Ç–∞—Ç—å –∫–Ω–∏–≥–∏", "topic": "üìö –•–æ–±–±–∏", "difficulty": "–ª–µ–≥–∫–æ", "explanation": "Present Simple –¥–ª—è –ø—Ä–∏–≤—ã—á–∫–∏."},
            {"id": 2, "en": "She works as a doctor", "ru": "–û–Ω–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤—Ä–∞—á–æ–º", "topic": "üíº –†–∞–±–æ—Ç–∞", "difficulty": "–ª–µ–≥–∫–æ", "explanation": "Present Simple, –ø–æ—Å–ª–µ she –¥–æ–±–∞–≤–ª—è–µ–º -s."},
        ]

def load_used_ids():
    try:
        if os.path.exists(USED_SENTENCES_FILE):
            with open(USED_SENTENCES_FILE, 'r') as f:
                return set(map(int, f.read().strip().split(','))) if f.read().strip() else set()
    except:
        pass
    return set()

def save_used_ids(used_ids):
    with open(USED_SENTENCES_FILE, 'w') as f:
        f.write(','.join(map(str, used_ids)))

def mark_as_used(sentence):
    used_ids = load_used_ids()
    if 'id' not in sentence:
        text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
        sentence['id'] = int(text_hash, 16) % 1000000
    used_ids.add(sentence['id'])
    save_used_ids(used_ids)

def is_used(sentence):
    used_ids = load_used_ids()
    if 'id' in sentence:
        return sentence['id'] in used_ids
    text_hash = hashlib.md5(sentence['en'].encode()).hexdigest()[:8]
    fake_id = int(text_hash, 16) % 1000000
    return fake_id in used_ids

# ===== –°–û–•–†–ê–ù–ï–ù–ò–ï –ü–û–°–õ–ï–î–ù–ï–ì–û –ü–†–ï–î–õ–û–ñ–ï–ù–ò–Ø =====
def save_last_sentence(sentence):
    with open(LAST_SENTENCE_FILE, 'w', encoding='utf-8') as f:
        json.dump(sentence, f, ensure_ascii=False, indent=2)
    print("‚úÖ –ü–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")

def load_last_sentence():
    if os.path.exists(LAST_SENTENCE_FILE):
        with open(LAST_SENTENCE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None

# ===== –ì–ï–ù–ï–†–ê–¶–ò–Ø =====
def generate_with_gemini():
    if not GEMINI_AVAILABLE or not GEMINI_KEY:
        return None
    try:
        client = genai.Client(api_key=GEMINI_KEY)
        prompt = """–¢—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —Ä–∞–∑–±–æ—Ä–æ–º.
        –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON:
        {"en": "...", "ru": "...", "topic": "...", "difficulty": "–ª–µ–≥–∫–æ/—Å—Ä–µ–¥–Ω–µ", "explanation": "..."}"""
        response = client.models.generate_content(model='models/gemini-1.5-flash', contents=prompt)
        return extract_json(response.text)
    except Exception as e:
        print(f"‚ö†Ô∏è Gemini –æ—à–∏–±–∫–∞: {type(e).__name__}")
        return None

def generate_with_cerebras():
    if not CEREBRAS_KEY:
        return None
    try:
        response = requests.post(
            CEREBRAS_URL,
            headers={"Authorization": f"Bearer {CEREBRAS_KEY}"},
            json={
                "model": "llama3.3-70b",
                "messages": [{"role": "user", "content": "–°–æ–∑–¥–∞–π JSON —Å en, ru, topic, explanation"}],
                "temperature": 0.8
            },
            timeout=20
        )
        if response.status_code == 200:
            return extract_json(response.json()['choices'][0]['message']['content'])
    except:
        return None

def generate_with_openrouter():
    if not OPENROUTER_KEY:
        return None
    try:
        response = requests.post(
            OPENROUTER_URL,
            headers={"Authorization": f"Bearer {OPENROUTER_KEY}"},
            json={
                "model": "openrouter/free",
                "messages": [{"role": "user", "content": "–°–æ–∑–¥–∞–π JSON —Å en, ru, topic, explanation"}]
            },
            timeout=20
        )
        if response.status_code == 200:
            return extract_json(response.json()['choices'][0]['message']['content'])
    except:
        return None

def get_unique_ai_sentence():
    providers = [
        ("Gemini", generate_with_gemini),
        ("Cerebras", generate_with_cerebras),
        ("OpenRouter", generate_with_openrouter)
    ]
    for name, func in providers:
        print(f"ü§ñ –ü—Ä–æ–±—É—é {name}...")
        sentence = func()
        if sentence and not is_used(sentence) and all(k in sentence for k in ['en','ru','topic','explanation']):
            print(f"‚úÖ {name} —Å—Ä–∞–±–æ—Ç–∞–ª!")
            return sentence
    return None

def get_unique_db_sentence():
    sentences = load_sentences()
    used = load_used_ids()
    available = [s for s in sentences if s['id'] not in used]
    if not available:
        save_used_ids(set())
        available = sentences
    return random.choice(available)

def send_telegram_message(text):
    if not BOT_TOKEN or not CHAT_ID:
        return None
    try:
        r = requests.post(
            f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage",
            data={'chat_id': CHAT_ID, 'text': text, 'parse_mode': 'HTML'},
            timeout=10
        )
        if r.status_code == 200 and r.json().get('ok'):
            print("‚úÖ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            return True
    except:
        pass
    return False

def main():
    print("\n" + "="*60)
    print("üöÄ –ó–ê–ü–£–°–ö –ë–û–¢–ê")
    print("="*60)
    
    print(f"ü§ñ Gemini: {'‚úÖ' if GEMINI_KEY else '‚ùå'}")
    print(f"ü§ñ Cerebras: {'‚úÖ' if CEREBRAS_KEY else '‚ùå'}")
    print(f"ü§ñ OpenRouter: {'‚úÖ' if OPENROUTER_KEY else '‚ùå'}")
    
    # –õ–æ–≥–∏–∫–∞: –≤ task –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º, –≤ answer –∑–∞–≥—Ä—É–∂–∞–µ–º
    if RUN_TYPE == 'task':
        print("\nüîç –ì–ï–ù–ï–†–ò–†–£–ï–ú –ù–û–í–û–ï...")
        sentence = get_unique_ai_sentence()
        if not sentence:
            sentence = get_unique_db_sentence()
        if not sentence:
            print("‚ùå –ù–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
            return
        
        save_last_sentence(sentence)
        mark_as_used(sentence)
        
        msg = f"üìù <b>–ï–ñ–ï–î–ù–ï–í–ù–´–ô –î–ò–ö–¢–ê–ù–¢</b>\n\n"
        msg += f"<b>–¢–µ–º–∞:</b> {sentence['topic']}\n"
        msg += f"<b>–°–ª–æ–∂–Ω–æ—Å—Ç—å:</b> {sentence.get('difficulty', '–ª–µ–≥–∫–æ')}\n\n"
        msg += f"üá¨üáß <b>–ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π:</b>\n"
        msg += f"<i>{sentence['en']}</i>\n\n"
        msg += f"‚è≥ <b>–û—Ç–≤–µ—Ç –∏ —Ä–∞–∑–±–æ—Ä –ø—Ä–∏–¥—É—Ç —á–µ—Ä–µ–∑ 10 –º–∏–Ω—É—Ç</b>"
        
        print("\nüì® –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ó–ê–î–ê–ù–ò–ï...")
        
    else:  # answer
        print("\nüîç –ó–ê–ì–†–£–ñ–ê–ï–ú –°–û–•–†–ê–ù–ï–ù–ù–û–ï...")
        sentence = load_last_sentence()
        if not sentence:
            print("‚ö†Ô∏è –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ...")
            sentence = get_unique_ai_sentence() or get_unique_db_sentence()
            if not sentence:
                print("‚ùå –ù–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
                return
        
        msg = f"üìù <b>–ü–†–û–í–ï–†–ö–ê –î–ò–ö–¢–ê–ù–¢–ê</b>\n\n"
        msg += f"üá¨üáß <b>–ë—ã–ª–æ:</b> {sentence['en']}\n"
        msg += f"üá∑üá∫ <b>–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥:</b>\n"
        msg += f"<i>{sentence['ru']}</i>\n\n"
        msg += f"üìä <b>–ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä:</b>\n"
        msg += f"{sentence.get('explanation', '–ú–æ–ª–æ–¥–µ—Ü!')}\n\n"
        msg += f"üí™ –û—Ç–ª–∏—á–Ω–æ–π —Ä–∞–±–æ—Ç—ã!"
        
        print("\nüì® –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –û–¢–í–ï–¢...")
    
    if send_telegram_message(msg):
        print("\n‚úÖ –í–°–Å –ì–û–¢–û–í–û")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏")
    print("="*60)

if __name__ == "__main__":
    main()
